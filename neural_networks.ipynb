{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using neural networks to classify cat and dog pictures\n",
    "\n",
    "In this tutorial, we are going to use machine learning to classify images! We will write a program that will automatically learn to recognize whether a picture is of a cat or dog.\n",
    "\n",
    "Here is a cat image:\n",
    "\n",
    "<img src='neural_assets/cat.jpg' width=250 alt=''/>\n",
    "\n",
    "Meow! I'm too fat and upside down. Classify me as a cat still, will you?\n",
    "\n",
    "Here is a dog image:\n",
    "\n",
    "<img src='neural_assets/dog.jpg' width=250 alt=''/>\n",
    "\n",
    "Bow, wow! I've got this toy in my mouth! Don't tell me I'm not a dog anymore!\n",
    "\n",
    "Recognizing whether a picture is of a cat or a dog used to be a difficult task for computers. One of the main reason for this was the fact that all the pictures to be recognized were quite different. If somebody wrote a program to detect a cat by sensing its eyes and ears in the middle of the image, the cat would outsmart the computer by choosing to appear in the top right corner of the image. This was irritating and computer scientists found it near impossible to write a program that could satisfactorily distinguish between all the possible cat and dog images.\n",
    "\n",
    "Neural networks (and specifically, an advanced type of them called convolutional neural networks) have come to solve to problem of image recognizition rather differently. First, these networks try to sense different features of the image from different parts of the image. In case of cat and dog images, these features would represent ears, eyes, body contours, tails, legs etc. Then, these features are used to determine what might be in the picture. For example, cats might have different ears in general than dogs, and neural network might be trained to use this information to distinguish between cat and dog images. In general, there can be hundreds or thousands of such facts on which the neural network can be trained. When we keep training neural networks with more and more data, they start recognizing the differences between the images and begin making correct guesses about what's in the image.\n",
    "\n",
    "So if we train a neural network with lots of cat and dog images, it should also start telling us whether the image we give to it is of a cat or a dog! In this tutorial, we are going to do exactly that, but before we begin, we will go through a short introduction of what neural networks are, and what are they made up of, and how are they trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A short introduction to neural networks\n",
    "\n",
    "Neural networks are machine learning algorithms that are inspired by our knowledge of brain function. Although, if you ask machine learning scientists, they might say that neural networks have little to do with how the brain works. Typically, these networks are made up of nodes, edges, and layers. Let us briefly see what each of them are.\n",
    "\n",
    "## Nodes\n",
    "\n",
    "Nodes are the fundamental unit of neural networks. Their main task is to take in some information, process it, and produce an output. For example, a node can take in a number, square it, and output it. Another node can take in 3 numbers, take their 5th root, and output them. Typically, a node takes one or inputs and gives one output. In pictures, a node looks like this:\n",
    "\n",
    "<img src='neural_assets/nodes.png'/>\n",
    "\n",
    "## Edges\n",
    "\n",
    "Edges carry information from one node to another. They take output of one node and feed that as input in another node. In this way, edges allow us to connect different together. For example, we can have three nodes connected to each other where input of first node gets processed by one node after another, and gets out at the end of third node:\n",
    "\n",
    "<img src='neural_assets/edges.png'/>\n",
    "\n",
    "We can see that when we input 5 in the first node, we get 1.44 as the output in the last node. Intermediate outputs of the nodes are shown in the diagram.\n",
    "\n",
    "## Layers\n",
    "\n",
    "Layers are made by putting many nodes together on top of each other. A layer typically takes in many inputs and generates many inputs. Technically, a layer is just a collection nodes and edges. Here is how a layer might look like in a neural netwrok:\n",
    "\n",
    "<img src='neural_assets/layer1.png'/>\n",
    "\n",
    "We can also criss cross inputs so that each input goes in all nodes. When that happens, the layer can look like this:\n",
    "\n",
    "<img src='neural_assets/layer2.png'/>\n",
    "\n",
    "You can imagine the criss crossing happening over and over, as the outputs of one layer become inputs of another. The layer above does simple computation, but other more advanced kind of layers do very specialized operations like applying filters to images, reducing image dimensionality etc. These kind of layers are typically employed in applications like image and speech recognizition. Although we will use these advanced type of layers in our example later, we will not cover them here.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "In a typical NN, there are many nodes and edges, connected to each other layer after layer. The manner in which these nodes and edges are connected is called the architecture of the neural network. Some networks are shallow and have fewer layers and some NNs are deep and have more layers. Deep learning refers to NNs with more layers. Here are some pictures of what shallow and deep nets look like:\n",
    "\n",
    "### A shallow neural network\n",
    "\n",
    "<img src='neural_assets/shallow_net.png' width=300/>\n",
    "\n",
    "### A deep neural network\n",
    "\n",
    "<img src='neural_assets/deep_net.png' width=500/>\n",
    "\n",
    "Source: https://synapse.koreamed.org/DOIx.php?id=10.3348/kjr.2017.18.4.570&vmode=PUBREADER\n",
    "\n",
    "## How does it work?\n",
    "\n",
    "Neural networks work in a simple manner: we pass the data to the input layer, and they keep going through hidden layers. At the end, the data reach the output layer and we get to see the final guess that the network has made about the input. But to bring a network to this stage, we need to train it. Training a network requires us to turn a lot of knobs or tuning parameters of the network that decide various things ranging from its architecture to activation functions. Let us go through these different tuning parameters in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to train your neural network?\n",
    "\n",
    "<img src='https://imgs.xkcd.com/comics/machine_learning.png'/>\n",
    "\n",
    "Training a neural network has been termed as more of an art than a science. The process requires a lot of trial and error and reconfiguring your network using different tuning parameters. Although there are sensible defaults for these parameters, optimizing their values often makes a difference.\n",
    "\n",
    "To train a neural network model, we first decide its architecture. Then, we initialize the netwrok nodes to make random predictions. After the initialization, we start feeding real data into the network. In the beginning, the network makes random predictions. But step after step, we start bending the nodes in such a way so that they make correct predictions. Besides deciding the architecture, the model training process requires us to prepare datasets and tune various parameters. These concepts are explained below.\n",
    "\n",
    "## Training and test sets\n",
    "\n",
    "After we train our neural network (or any other machine learning model) on data, we need to assess its accuracy. If we assess the model accuracy on the data on which we trained it, we will get an overly optimistic estimate. To remedy this problem, the machine learning dataset is often split into two parts: training set and test set. Training set data are used to train the model, and once the training is done, the test set data are given to the model to generate predictions. Then, these predictions are matched back to the original answers from the test set. This process gives us a more accurate estimate of the model accuracy.\n",
    "\n",
    "<img src='https://sites.google.com/a/kingofat.com/wiki/_/rsrc/1242169530969/data-mining/classification/Picture%2020.png'/>\n",
    "\n",
    "Source: https://sites.google.com/a/kingofat.com/wiki/_/rsrc/1242169530969/data-mining/classification/Picture%2020.png\n",
    "\n",
    "## Underfitting and overfitting\n",
    "\n",
    "Sometimes, we might end up with a model that performs really well on the training set, but performs poorly on the test set. This is called overfitting the training set. The opposite of overfitting is called underfitting, where the model does not use all the information in the training set and performs poorly even on the training set.\n",
    "\n",
    "<img src='https://vitalflux.com/wp-content/uploads/2015/02/fittings.jpg'/>\n",
    "\n",
    "Source: https://vitalflux.com/wp-content/uploads/2015/02/fittings.jpg\n",
    "\n",
    "## Epoch\n",
    "\n",
    "When we are training the model, an epoch refers to one cycle through all the training set data points. In epoch 1, the model will make many errors, but in epoch 100, we can expect the model to make fewer errors.\n",
    "\n",
    "## Learning rate\n",
    "\n",
    "Learning rate determines how fast we want our network to learn from data. As our network learns more and more facts from data, it makes fewer errors (or loss). But if we allow it to learn too quickly, it might end up making more erors as the training goes on. For this reason, we need to pick a training rate that is optimal for our network.\n",
    "\n",
    "<img src='http://cs231n.github.io/assets/nn3/learningrates.jpeg'/>\n",
    "\n",
    "Source: http://cs231n.github.io/assets/nn3/learningrates.jpeg\n",
    "\n",
    "## Activation\n",
    "\n",
    "One of the most important things we need to set for neural network training is our choice of the activation function. This function is applied to the output of each node, and can make a significant difference to time taken to train the network. There are many different kind of functions. Three most common functions are depicted below:\n",
    "\n",
    "<img src='http://adilmoujahid.com/images/activation.png'/>\n",
    "\n",
    "Source: http://adilmoujahid.com/images/activation.png\n",
    "\n",
    "You can also use Linear function, which does not apply any function on the node output.\n",
    "\n",
    "## Regularization\n",
    "\n",
    "Regularization is one way to avoid overfitting. L1 and L2 are most common type of regularizations used. Essentially, what they do is penalize the model for learning too much from data.\n",
    "\n",
    "### Regularization rate\n",
    "\n",
    "Regularization rate refers to the importance we want to give to the regularization. A low value means that we want to do little regularization, while a high value means that we want to do too much of it. We must ensure that this value is not too low or too high, but just right. The example below shows that a low value for regularization ends up with a model that overfits the data (left panel), model on the right panel might be underfitting :\n",
    "\n",
    "<img src='http://cs231n.github.io/assets/nn1/reg_strengths.jpeg'/>\n",
    "\n",
    "Source: http://cs231n.github.io/assets/nn1/reg_strengths.jpeg\n",
    "\n",
    "## Batch size\n",
    "\n",
    "Sometimes when training the network, we might not feed all the data to the network in one go. Batch size refers to the number of data points that we feed to the network before we adjust or bend the nodes to predict correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How will we use neural networks to classify images?\n",
    "\n",
    "In any machine learning project, bulk of the work happens before we start using algorithms like neural networks. So before we begin using neural networks to classify images, we will have to do what is generally called data preparation. Doing it will bring the data in a format that can be fed to a machine learning algorithm. After the data preparation, we will split data into training and test sets. We will using training set to train our model and test set to assess the accuracy of our model. Remember, it is important to assess the accuracy of the model with test set!\n",
    "\n",
    "* Data preparation\n",
    "* Data splitting (into training and test sets)\n",
    "* Model building (on the training set)\n",
    "* Model validation (on the test set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"this\"\n"
     ]
    }
   ],
   "source": [
    "print(\"this\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
