{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using neural networks to classify cat and dog pictures\n",
    "\n",
    "In this tutorial, we are going to use machine learning to classify images! We will write a program that will automatically learn to recognize whether a picture is of a cat or dog. Although it might sound simple, recognizing whether a picture is of a cat or a dog used to be a difficult task for computers. One of the main reason for this was the fact that all the pictures to be recognized were quite different. If somebody wrote a program to detect a cat by sensing its eyes and ears in the middle of the image, the cat would outsmart the computer by choosing to appear in the top right corner of the image. This was irritating and computer scientists found it near impossible to write a program that could satisfactorily distinguish between all the possible cat and dog images.\n",
    "\n",
    "<img src='neural_assets/cat.jpg' width=250 />\n",
    "\n",
    "Meow! I'm too fat and upside down. Classify me as a cat still, will you?\n",
    "\n",
    "<img src='neural_assets/dog.jpg' width = 250 />\n",
    "\n",
    "Bow, wow! I've got this toy in my mouth! Don't tell me I'm not a dog anymore!\n",
    "\n",
    "Neural networks (and specifically, an advanced type of them called convolutional neural networks) have come to solve to problem of image recognizition rather differently. First, these networks try to sense different features of the image from different parts of the image. In case of cat and dog images, these features would represent ears, eyes, body contours, tails, legs etc. Then, these features are used to determine what might be in the picture. For example, cats might have different looking ears in general than dogs, and neural network might be trained to use this information to distinguish between cat and dog images. There can be hundreds or thousands of such facts on which the neural network can be trained. When we keep training neural networks with more and more data, they start recognizing the differences between the images and begin making correct guesses about what's in the image.\n",
    "\n",
    "So if we train a neural network with lots of cat and dog images, it will also start telling us whether the image we give to it is of a cat or a dog! So in this tutorial, we are going to do exactly that. But before we begin, we will go through a short introduction of what neural networks are made up of, and how are they trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A short introduction to neural networks\n",
    "\n",
    "Neural networks are machine learning algorithms that are inspired by our knowledge of brain function. Although if you ask a machine learning scientist, she might say that neural networks have little to do with how the brain works. Whether neural networks have anything to with the brain or not, they are almost always made up of many nodes, edges, and layers. If you have been searching about neural networks online or otherwise, you must have seen images like this:\n",
    "\n",
    "<img src='neural_assets/sample_net.png'/>\n",
    "\n",
    "Source: http://www.opennn.net/images/deep_neural_network.png\n",
    "\n",
    "In the image above, the circles are called nodes, the lines are called edges, and the verticle stacks of nodes are called layers. Let us briefly review anatomy and function of these elements.\n",
    "\n",
    "## Nodes\n",
    "\n",
    "Nodes are the fundamental unit of neural networks. Their main task is to take in some information, process it, and produce an output. For example, a node can take in a number, square it, and output it. Another node can take in 3 numbers, take their 5th root, and output them. Typically, a node takes one or more inputs and gives one output. This output can go in one or more nodes. In pictures, a node looks like this:\n",
    "\n",
    "<img src='neural_assets/nodes.png'/>\n",
    "\n",
    "## Edges\n",
    "\n",
    "Edges carry information from one node to another. They take output of one node and feed that as input in one or more nodes. In this way, edges allow us to connect different together. For example, we can have three nodes connected to each other where input of first node gets processed by one node after another, and gets out at the end of third node:\n",
    "\n",
    "<img src='neural_assets/edges.png'/>\n",
    "\n",
    "We can see that when we input 5 in the first node, we get 1.44 as the output in the last node. Intermediate outputs of the nodes are shown in the diagram.\n",
    "\n",
    "## Layers\n",
    "\n",
    "Layers are made by putting many nodes together on top of each other. A layer typically takes in many inputs and generates many inputs. Technically, a layer is just a collection nodes and edges. Here is how a layer might look like in a neural netwrok:\n",
    "\n",
    "<img src='neural_assets/layer1.png'/>\n",
    "\n",
    "We can also criss cross inputs so that each input goes in all nodes. When that happens, the layer can look like this:\n",
    "\n",
    "<img src='neural_assets/layer2.png'/>\n",
    "\n",
    "When the outputs are criss crossed, it looks like this:\n",
    "\n",
    "<img src='neural_assets/layer3.png'/>\n",
    "\n",
    "You can imagine the criss crossing happening over and over, as the outputs of one layer become inputs of another. The layer above does simple computation, but other more advanced kind of layers do very specialized operations like applying filters to images, reducing image dimensionality etc. These kind of layers are typically employed in applications like image and speech recognizition. Although we will use these advanced type of layers in our example later, we will not cover them here.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "In a typical neural network, there are many nodes and edges, connected to each other layer after layer. The manner in which these nodes and edges are connected is called the architecture of the neural network. Some networks are shallow and have fewer layers and some NNs are deep and have more layers. Deep learning refers to doing machine learning with neural networks that have more than a few layers. Here are some pictures of what shallow and deep nets look like:\n",
    "\n",
    "### A shallow neural network\n",
    "\n",
    "<img src='neural_assets/shallow_net.png' width=300/>\n",
    "\n",
    "### A deep neural network\n",
    "\n",
    "<img src='neural_assets/deep_net.png' width=500/>\n",
    "\n",
    "Source: https://synapse.koreamed.org/DOIx.php?id=10.3348/kjr.2017.18.4.570&vmode=PUBREADER\n",
    "\n",
    "Whether you should use a shallow net or deep net depends on your dataset. There is no one architecture that works well on all the different datasets, and the network structure is often decided by trial and error.\n",
    "\n",
    "## How does it work?\n",
    "\n",
    "Neural networks work in a simple manner: we pass the data to the input layer, and they keep going through hidden layers. At the end, the data reach the output layer and we get to see the final guess that the network has made about the input. But to bring a network to this stage, we need to train it. Training a network requires us to turn a lot of knobs or tuning parameters of the network that decide various things ranging from its architecture to activation functions. Let us go through these different tuning parameters in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to train your neural network?\n",
    "\n",
    "Training a neural network has been termed as more of an art than a science. The process requires a lot of trial and error and reconfiguring your network using different tuning parameters. Although there are sensible defaults for these parameters, optimizing their values often makes a difference.\n",
    "\n",
    "<img src='https://imgs.xkcd.com/comics/machine_learning.png'/>\n",
    "\n",
    "To train a neural network model, we first decide its architecture. Then, we initialize the netwrok nodes to make random predictions. After the initialization, we start feeding real data into the network. In the beginning, the network makes random predictions. But step after step, we start bending the nodes in such a way so that the computations they do lead to correct predictions. Besides deciding the architecture, the model training process requires us to prepare datasets and tune various parameters. These concepts and some other important terms in machine learning jargon are explained below.\n",
    "\n",
    "## Training and test sets\n",
    "\n",
    "Before training the model, data are typically split in two sets: a training set and a test set. This is mainly done so that we can get an honest estimate of model accuracy. If we assess the model accuracy on the data on which we trained it, we will get an overly optimistic estimate. So training set data are used to train the model, and once the training is done, the test set data are given to the model to generate predictions. Then, these predictions are matched back to the original answers from the test set to calculate test accuracy.\n",
    "\n",
    "<img src='https://sites.google.com/a/kingofat.com/wiki/_/rsrc/1242169530969/data-mining/classification/Picture%2020.png'/>\n",
    "\n",
    "Source: https://sites.google.com/a/kingofat.com/wiki/_/rsrc/1242169530969/data-mining/classification/Picture%2020.png\n",
    "\n",
    "This process gives us a more accurate estimate of the model accuracy.\n",
    "\n",
    "## Decision boundary\n",
    "\n",
    "A decision boundary is used to decide what class we should assign to a data point. Generally, all the classifiers try to learn a decision boundary from data, and use that boundary for all the future predictions.\n",
    "\n",
    "<img src='neural_assets/boundary.png' width=500/>\n",
    "\n",
    "Source: https://i.stack.imgur.com/LZWS8.png\n",
    "\n",
    "In the image above, the circle depicts a decision boundary. All the points inside the circle will be predicted to be from the green class, and all the points outside will be predicted to be from the red class. As you can see, this might lead to some error - but machine learning is always noisy and never free of error.\n",
    "\n",
    "## Overfitting and underfitting\n",
    "\n",
    "Sometimes, we might end up with a model that performs really well on the training set, but performs poorly on the test set. This is called overfitting the training set. The opposite of overfitting is called underfitting, where the model does not use all the information in the training set and performs poorly even on the training set.\n",
    "\n",
    "<img src='https://vitalflux.com/wp-content/uploads/2015/02/fittings.jpg'/>\n",
    "\n",
    "Source: https://vitalflux.com/wp-content/uploads/2015/02/fittings.jpg\n",
    "\n",
    "In the image above, the oncepts of overfitting and underfitting are depicted. You can see how decision boundary is suboptimal in case of overfitting and unerfitting, while in between both the extremes, there is a 'just right' kind of decision boundary that might end up performing well.\n",
    "\n",
    "## Epoch\n",
    "\n",
    "To train our neural network model, we iteratively go through the training set and keep adjusting various node parameters until a we reach a satisfactory point. In the model training process, an epoch refers to one cycle through the training data. In epoch 1, the model will make many errors, but in epoch 100, we can expect the model to make fewer errors.\n",
    "\n",
    "## Learning rate\n",
    "\n",
    "Learning rate determines how fast we want our network to learn from data. As our network learns more and more facts from data, it makes fewer errors (or loss). But if we allow it to learn too quickly, it might end up making more erors as the training goes on. For this reason, we need to pick a training rate that is optimal for our network.\n",
    "\n",
    "<img src='http://cs231n.github.io/assets/nn3/learningrates.jpeg'/>\n",
    "\n",
    "Source: http://cs231n.github.io/assets/nn3/learningrates.jpeg\n",
    "\n",
    "## Activation\n",
    "\n",
    "One of the most important things we need to set for neural network training is our choice of the activation function. This function is applied to the output of each node, and can make a significant difference to time taken to train the network. There are many different kind of activation functions, but the most common ones (sigmoid, tanh, ReLu) are depicted below:\n",
    "\n",
    "<img src='http://adilmoujahid.com/images/activation.png'/>\n",
    "\n",
    "Source: http://adilmoujahid.com/images/activation.png\n",
    "\n",
    "You can also use Linear function, which does not apply any function on the node output.\n",
    "\n",
    "## Regularization\n",
    "\n",
    "Regularization is one way to avoid overfitting. L1 and L2 are most common type of regularizations used. Essentially, what they do is penalize the model for learning too much from data thereby reducing the chance of overfitting.\n",
    "\n",
    "### Regularization rate\n",
    "\n",
    "Regularization rate refers to the importance or weight we want to give to the regularization. A low value means that we want to do little regularization, while a high value means that we want to do too much of it. We must ensure that this value is not too low or too high, but just right. The example below shows that a low value for regularization ends up with a model that overfits the data (left panel), while a high value leads to a model that underfits the data (right panel):\n",
    "\n",
    "<img src='http://cs231n.github.io/assets/nn1/reg_strengths.jpeg'/>\n",
    "\n",
    "Source: http://cs231n.github.io/assets/nn1/reg_strengths.jpeg\n",
    "\n",
    "## Batch size\n",
    "\n",
    "Sometimes when training the network, we might not feed all the data to the network in one go. Batch size refers to the number of data points that we feed to the network before we adjust the node parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's tinker with some neural networks!\n",
    "\n",
    "Before we jump into the sea of cats and dogs, let us play with some simple neural networks in Tensorflow Playground.\n",
    "\n",
    "Open this URL: http://playground.tensorflow.org\n",
    "\n",
    "You will see a neural network with many settings, most of which you should now be slighly familiar with if you have been closely following the tutorial. We have prepared two set of examples here that will illustrate some of the concepts we have discussed so far. You can try others yourself. Both example sets will try to classify dots on a plane to their correct class (orange v/s blue) using their coordinates:\n",
    "\n",
    "<img src='neural_assets/nn_dots_example.png'/>\n",
    "\n",
    "## Example set 1: Bad parameters\n",
    "\n",
    "In this set of examples, we have chosen bad parameters for the neural network. These parameters will not allow neural network to learn the optimal decision boundary, as you will see yourself.\n",
    "\n",
    "### Example 1.1: High learning rate\n",
    "\n",
    "This example has a learning rate of 3.\n",
    "\n",
    "URL: <a href='http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=3&regularizationRate=0&noise=0&networkShape=4,2&seed=0.43188&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false'>Click here</a>\n",
    "\n",
    "### Example 1.2: Sparse architecture\n",
    "\n",
    "This example only has two neurons in first hidden layer.\n",
    "\n",
    "URL: <a href='http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=1&regularizationRate=0&noise=0&networkShape=2,2&seed=0.43188&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false'>Click here</a>\n",
    "\n",
    "### Example 1.3: Unsuitable activation function\n",
    "\n",
    "This example uses sigmoid activation function which takes way too many epochs to reach a good decision boundary.\n",
    "\n",
    "URL: <a href='http://playground.tensorflow.org/#activation=sigmoid&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.77764&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false'>Click here</a>\n",
    "\n",
    "## Example set 2: Good parameters\n",
    "\n",
    "In this set of examples, we will provide counter examples to the examples provided above.\n",
    "\n",
    "### Example 2.1: Good learning rate\n",
    "\n",
    "With a relatively high learning rate a bit of a regularization, the network learns a fair decision boundary very quickly!\n",
    "\n",
    "URL: <a href='http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.3&regularizationRate=0.1&noise=0&networkShape=4,2&seed=0.77764&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false'>Click here</a>\n",
    "\n",
    "### Example 2.2: Dense architecture\n",
    "\n",
    "When we increase the number of hidden units and neurons, we learn a close to perfect decision boundary.\n",
    "\n",
    "URL: <a href='http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.1&regularizationRate=0&noise=0&networkShape=6,4,3&seed=0.77764&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false'>Click here</a>\n",
    "\n",
    "### Example 2.3: Suitable activation function\n",
    "\n",
    "Now we use ReLu activation function, and you will see that with ReLu it takes a really short time to get at a good decision boundary.\n",
    "\n",
    "URL: <a href='http://playground.tensorflow.org/#activation=relu&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.17505&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false'>Click here</a>\n",
    "\n",
    "Feel free to make more changes in the playground as you wish. Some of the things to do are:\n",
    "\n",
    "* Change regularization types and rates\n",
    "* Change batch size\n",
    "* Change architecture\n",
    "* Change features\n",
    "* Change datasets\n",
    "\n",
    "When you are done, come back! We still have to build our own neural network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to train our own neural network\n",
    "\n",
    "In this final part of the tutorial, we will build our own neural network to tell whether a given picture is of a cat or of a dog. If the picture has neither of them, our algorithm will still tell us what it thinks about the picture (% confidence that there is a cat/dog in the picture).\n",
    "\n",
    "In any machine learning project, bulk of the work happens before we start using algorithms like neural networks. So before we begin using neural networks to classify images, we will have to do what is generally called data preparation. Doing it will bring the data in a format that can be fed to a machine learning algorithm. After the data preparation, we will split data into training and test sets. We will using training set to train our model and test set to assess the accuracy of our model. Remember, it is important to assess the accuracy of the model with test set!\n",
    "\n",
    "* Data preparation\n",
    "* Data splitting (into training and test sets)\n",
    "* Model building (on the training set)\n",
    "* Model validation (on the test set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
